{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical Neural Networks Homework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_Ma2HpvQc51",
        "colab_type": "text"
      },
      "source": [
        "# Classifying cancer expression vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW0BIgD8Qc55",
        "colab_type": "text"
      },
      "source": [
        "In this assignment you will train a neural network to identify the tissue type that produced an RNA expression vector. The dataset is comprised of RNA-seq data obtained from tumors. \n",
        "\n",
        "For a complete description of the data collection workflow see this page:\n",
        "https://xenabrowser.net/datapages/?host=https://toil.xenahubs.net\n",
        "\n",
        "And for the corresponding publication:\n",
        "https://doi.org/10.1038/nbt.3772"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oGeS7--cQc56",
        "colab_type": "code",
        "outputId": "93c3bf56-2342-4b1d-fd8c-713b0f387d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"USING pytorch VERSION: \", torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "USING pytorch VERSION:  1.0.1.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS7Ix_lFQc6L",
        "colab_type": "text"
      },
      "source": [
        "## Loading and parsing training data\n",
        "For this problem, expression data needs to be loaded and pruned. Initially, there are >50,000 genes in each expression vector, which can be reduced to a much smaller gene set for the sake of minimizing computation time. Here, the data is subsetted to only include genes from the KEGG gene set. You may want to consider reducing or expanding this dataset to get a better understanding of which genes are predictive, though this is not a requirement for the assignment.\n",
        "\n",
        "For a list of gene sets, check out the MSigDB collections page: http://software.broadinstitute.org/gsea/msigdb/collections.jsp\n",
        "\n",
        "This script was adapted from Rob Currie's ingestion script: https://github.com/rcurrie/tumornormal/blob/master/genesets.ipynb\n",
        "\n",
        "We have placed a subset of this data for this homework in Google drive, you can download it here:\n",
        "\n",
        "https://drive.google.com/drive/folders/1pPABQDEHCddPTJAhfD6G5KyBDJiK3unQ?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnhNSCGW5FHO",
        "colab_type": "code",
        "outputId": "8f2b6f91-050d-4bc7-836e-3d7d8e1d27e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "# Load the data - If using Google drive link to access data the following with connect\n",
        "# to drive, authenticate using your Google account and load the data\n",
        "\n",
        "!pip install -U -q PyDrive ## you will have install for every colab session\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#x_test: https://drive.google.com/file/d/1Cc4zEw1wANFX8S44L87Rx_EZWwCcONMW/view?usp=sharing\n",
        "#x_train: https://drive.google.com/file/d/1s8VvRaUc62OYukRunV689Y9u-v_y7KRl/view?usp=sharing\n",
        "#y_test: https://drive.google.com/file/d/1W4Qdr3zm5QYGP5ncMQSurrO1m05KsKQ2/view?usp=sharing\n",
        "#t_train: https://drive.google.com/file/d/1UmDZ25W84DmIY4im2XHCAc5QGgNkdexD/view?usp=sharing\n",
        "\n",
        "# 2. Now proxy the Google Drive files to a local file\n",
        "x_test_import = drive.CreateFile({'id':'1Cc4zEw1wANFX8S44L87Rx_EZWwCcONMW'})\n",
        "x_train_import = drive.CreateFile({'id':'1s8VvRaUc62OYukRunV689Y9u-v_y7KRl'})\n",
        "y_test_import = drive.CreateFile({'id':'1W4Qdr3zm5QYGP5ncMQSurrO1m05KsKQ2'})\n",
        "y_train_import = drive.CreateFile({'id':'1UmDZ25W84DmIY4im2XHCAc5QGgNkdexD'})\n",
        "\n",
        "x_test_import.GetContentFile('x_test.npz') # x_test.npz is the file name that will be accessible in the notebook.\n",
        "x_train_import.GetContentFile('x_train.npz') # x_train.npz is the file name that will be accessible in the notebook.\n",
        "y_test_import.GetContentFile('y_test.npz') # y_test.npz is the file name that will be accessible in the notebook.\n",
        "y_train_import.GetContentFile('y_train.npz') # y_train.npz is the file name that will be accessible in the notebook.\n",
        "\n",
        "y_index_key = {'Adipose Tissue': 0, 'Adrenal Gland': 1, 'Adrenal gland': 2, 'Bile duct': 3, 'Bladder': 4, 'Blood': 5, 'Blood Vessel': 6, 'Bone Marrow': 7, 'Brain': 8, 'Breast': 9, 'Cervix': 10, 'Cervix Uteri': 11, 'Colon': 12, 'Endometrium': 13, 'Esophagus': 14, 'Eye': 15, 'Fallopian Tube': 16, 'Head and Neck region': 17, 'Heart': 18, 'Kidney': 19, 'Lining of body cavities': 20, 'Liver': 21, 'Lung': 22, 'Lymphatic tissue': 23, 'Muscle': 24, 'Nerve': 25, 'Ovary': 26, 'Pancreas': 27, 'Paraganglia': 28, 'Pituitary': 29, 'Prostate': 30, 'Rectum': 31, 'Salivary Gland': 32, 'Skin': 33, 'Small Intestine': 34, 'Soft tissue,Bone': 35, 'Spleen': 36, 'Stomach': 37, 'SympatheticÊNervous System': 38, 'Testis': 39, 'Thymus': 40, 'Thyroid': 41, 'Thyroid Gland': 42, 'Uterus': 43, 'Vagina': 44, 'White blood cell': 45}\n",
        "\n",
        "for name in y_index_key:\n",
        "  print(name, y_index_key[name])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adipose Tissue 0\n",
            "Adrenal Gland 1\n",
            "Adrenal gland 2\n",
            "Bile duct 3\n",
            "Bladder 4\n",
            "Blood 5\n",
            "Blood Vessel 6\n",
            "Bone Marrow 7\n",
            "Brain 8\n",
            "Breast 9\n",
            "Cervix 10\n",
            "Cervix Uteri 11\n",
            "Colon 12\n",
            "Endometrium 13\n",
            "Esophagus 14\n",
            "Eye 15\n",
            "Fallopian Tube 16\n",
            "Head and Neck region 17\n",
            "Heart 18\n",
            "Kidney 19\n",
            "Lining of body cavities 20\n",
            "Liver 21\n",
            "Lung 22\n",
            "Lymphatic tissue 23\n",
            "Muscle 24\n",
            "Nerve 25\n",
            "Ovary 26\n",
            "Pancreas 27\n",
            "Paraganglia 28\n",
            "Pituitary 29\n",
            "Prostate 30\n",
            "Rectum 31\n",
            "Salivary Gland 32\n",
            "Skin 33\n",
            "Small Intestine 34\n",
            "Soft tissue,Bone 35\n",
            "Spleen 36\n",
            "Stomach 37\n",
            "SympatheticÊNervous System 38\n",
            "Testis 39\n",
            "Thymus 40\n",
            "Thyroid 41\n",
            "Thyroid Gland 42\n",
            "Uterus 43\n",
            "Vagina 44\n",
            "White blood cell 45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5u_LlXvQc6V",
        "colab_type": "text"
      },
      "source": [
        "## Define a pytorch Dataset object to contain the training and testing data\n",
        "Pytorch handles data shuffling and batch loading, as long as the user provides a \"Dataset\" class. This class is just a wrapper for your data that casts the data into pytorch tensor format and returns slices of the data. In this case, our data has been stored in numpy format, which conveniently pytorch has a method for converting to their native format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLJ6bZveQc6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PrimarySiteDataset(Dataset):\n",
        "    def __init__(self, x_path, y_path, batch_size=None):\n",
        "        x = np.load(x_path)['a']\n",
        "        y = np.load(y_path)['a']\n",
        "\n",
        "        x_dtype = torch.FloatTensor\n",
        "        y_dtype = torch.FloatTensor     # for MSE Loss\n",
        "\n",
        "        self.length = x.shape[0]\n",
        "\n",
        "        self.x_data = torch.from_numpy(x).type(x_dtype)\n",
        "        self.y_data = torch.from_numpy(y).type(y_dtype)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37Wx6Ui_NN7H",
        "colab_type": "text"
      },
      "source": [
        "## Define training methods for the model\n",
        "These methods use an initialized model and training data to iteratively perform the forward and backward pass of optimization. Aside from some data reformatting that depends on the input, output, and loss function, these methods will always be the same for any shallow neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hntQhyUWNOL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(model, x, y, optimizer, loss_fn):\n",
        "    # Run forward calculation\n",
        "    y_predict = model.forward(x)\n",
        "\n",
        "    # Compute loss.\n",
        "    loss = loss_fn(y_predict, y)\n",
        "\n",
        "    # Before the backward pass, use the optimizer object to zero all of the\n",
        "    # gradients for the variables it will update (which are the learnable weights\n",
        "    # of the model)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    # parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Calling the step function on an Optimizer makes an update to its\n",
        "    # parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.data.item()\n",
        "\n",
        "\n",
        "def train(model, loader, optimizer, loss_fn, epochs=5):\n",
        "    losses = list()\n",
        "\n",
        "    batch_index = 0\n",
        "    for e in range(epochs):\n",
        "        for x, y in loader:\n",
        "            loss = train_batch(model=model, x=x, y=y, optimizer=optimizer, loss_fn=loss_fn)\n",
        "            losses.append(loss)\n",
        "\n",
        "            batch_index += 1\n",
        "\n",
        "        print(\"Epoch: \", e+1)\n",
        "        print(\"Batches: \", batch_index)\n",
        "\n",
        "    return losses\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}